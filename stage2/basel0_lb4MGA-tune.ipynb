{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02859b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train3 from 2: use adam, remove weight_decay; one BW channel (not 3)\n",
    "import torch,os,glob\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nets import ResNet18_lbCM\n",
    "from tqdm import tqdm\n",
    "from configparser import ConfigParser\n",
    "from torch.utils.data import  DataLoader\n",
    "from LIDC_Mpad_data import LIDC_Dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d8dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "best_epoch = 0\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "prep_tr = [\n",
    "    v2.Lambda(lambda x: tv_tensors.Image(torch.clamp(x,-1000.,400.)) if isinstance(x, tv_tensors.Image) else x),\n",
    "    v2.Lambda(lambda x: tv_tensors.Image((x+1000)/1400) if isinstance(x, tv_tensors.Image) else x),\n",
    "    v2.CenterCrop((384,384)),\n",
    "]\n",
    "aug_tr = [\n",
    "    v2.RandomAffine(degrees=10),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "]\n",
    "trans_train = v2.Compose( prep_tr + aug_tr )\n",
    "trans_test = v2.Compose( prep_tr  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b344e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_data: 5495 total_test_data: 2354\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = ConfigParser()\n",
    "parser.read('.settings')\n",
    "root_dir = parser.get('dataset','root_dir') #/workspaces/data/lidc-idri/slices\n",
    "meta_dir = parser.get('dataset','meta_dir') #/workspaces/data/lidc-idri/splits\n",
    "result_dir = os.path.join(parser.get('dataset','result_dir'),'stage2/basel0_lb4MGA-tune')\n",
    "if not os.path.isdir(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "\n",
    "train_data = LIDC_Dataset(root_dir,metapath=os.path.join(meta_dir,'trainBB_malB.csv'),transform=trans_train, loadBB=True)\n",
    "test_data = LIDC_Dataset(root_dir,metapath=os.path.join(meta_dir,'testBB_malB.csv'),transform=trans_test)\n",
    "total_train_data = len(train_data)\n",
    "total_test_data = len(test_data)\n",
    "print('total_train_data:',total_train_data, 'total_test_data:',total_test_data)\n",
    "\n",
    "batch_size = int(parser['dataset']['batch_size'])\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94805703",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18_lbCM(pretrained=True,attr=\"LA4_BL2\")\n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "net.fc = nn.Linear(net.fc.in_features, 2)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a2f9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ResNet18_lbCM                                      [32, 2]                   --\n",
       "├─Conv2d: 1-1                                      [32, 64, 192, 192]        3,136\n",
       "├─BatchNorm2d: 1-2                                 [32, 64, 192, 192]        128\n",
       "├─ReLU: 1-3                                        [32, 64, 192, 192]        --\n",
       "├─MaxPool2d: 1-4                                   [32, 64, 96, 96]          --\n",
       "├─Sequential: 1-5                                  [32, 64, 96, 96]          --\n",
       "│    └─BasicBlock: 2-1                             [32, 64, 96, 96]          --\n",
       "│    │    └─Conv2d: 3-1                            [32, 64, 96, 96]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2                       [32, 64, 96, 96]          128\n",
       "│    │    └─ReLU: 3-3                              [32, 64, 96, 96]          --\n",
       "│    │    └─Conv2d: 3-4                            [32, 64, 96, 96]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5                       [32, 64, 96, 96]          128\n",
       "│    │    └─ReLU: 3-6                              [32, 64, 96, 96]          --\n",
       "│    └─BasicBlock: 2-2                             [32, 64, 96, 96]          --\n",
       "│    │    └─Conv2d: 3-7                            [32, 64, 96, 96]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8                       [32, 64, 96, 96]          128\n",
       "│    │    └─ReLU: 3-9                              [32, 64, 96, 96]          --\n",
       "│    │    └─Conv2d: 3-10                           [32, 64, 96, 96]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11                      [32, 64, 96, 96]          128\n",
       "│    │    └─ReLU: 3-12                             [32, 64, 96, 96]          --\n",
       "├─Sequential: 1-6                                  [32, 128, 48, 48]         --\n",
       "│    └─BasicBlock: 2-3                             [32, 128, 48, 48]         --\n",
       "│    │    └─Conv2d: 3-13                           [32, 128, 48, 48]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14                      [32, 128, 48, 48]         256\n",
       "│    │    └─ReLU: 3-15                             [32, 128, 48, 48]         --\n",
       "│    │    └─Conv2d: 3-16                           [32, 128, 48, 48]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17                      [32, 128, 48, 48]         256\n",
       "│    │    └─Sequential: 3-18                       [32, 128, 48, 48]         8,448\n",
       "│    │    └─ReLU: 3-19                             [32, 128, 48, 48]         --\n",
       "│    └─BasicBlock: 2-4                             [32, 128, 48, 48]         --\n",
       "│    │    └─Conv2d: 3-20                           [32, 128, 48, 48]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21                      [32, 128, 48, 48]         256\n",
       "│    │    └─ReLU: 3-22                             [32, 128, 48, 48]         --\n",
       "│    │    └─Conv2d: 3-23                           [32, 128, 48, 48]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24                      [32, 128, 48, 48]         256\n",
       "│    │    └─ReLU: 3-25                             [32, 128, 48, 48]         --\n",
       "├─Sequential: 1-7                                  [32, 256, 24, 24]         --\n",
       "│    └─BasicBlock: 2-5                             [32, 256, 24, 24]         --\n",
       "│    │    └─Conv2d: 3-26                           [32, 256, 24, 24]         294,912\n",
       "│    │    └─BatchNorm2d: 3-27                      [32, 256, 24, 24]         512\n",
       "│    │    └─ReLU: 3-28                             [32, 256, 24, 24]         --\n",
       "│    │    └─Conv2d: 3-29                           [32, 256, 24, 24]         589,824\n",
       "│    │    └─BatchNorm2d: 3-30                      [32, 256, 24, 24]         512\n",
       "│    │    └─Sequential: 3-31                       [32, 256, 24, 24]         33,280\n",
       "│    │    └─ReLU: 3-32                             [32, 256, 24, 24]         --\n",
       "│    └─BasicBlock: 2-6                             [32, 256, 24, 24]         --\n",
       "│    │    └─Conv2d: 3-33                           [32, 256, 24, 24]         589,824\n",
       "│    │    └─BatchNorm2d: 3-34                      [32, 256, 24, 24]         512\n",
       "│    │    └─ReLU: 3-35                             [32, 256, 24, 24]         --\n",
       "│    │    └─Conv2d: 3-36                           [32, 256, 24, 24]         589,824\n",
       "│    │    └─BatchNorm2d: 3-37                      [32, 256, 24, 24]         512\n",
       "│    │    └─ReLU: 3-38                             [32, 256, 24, 24]         --\n",
       "├─Sequential: 1-8                                  [32, 512, 12, 12]         --\n",
       "│    └─BasicBlock: 2-7                             [32, 512, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-39                           [32, 512, 12, 12]         1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40                      [32, 512, 12, 12]         1,024\n",
       "│    │    └─ReLU: 3-41                             [32, 512, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-42                           [32, 512, 12, 12]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43                      [32, 512, 12, 12]         1,024\n",
       "│    │    └─Sequential: 3-44                       [32, 512, 12, 12]         132,096\n",
       "│    │    └─ReLU: 3-45                             [32, 512, 12, 12]         --\n",
       "│    └─CBAMBasicBlockWithMask: 2-8                 [32, 512, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-46                           [32, 512, 12, 12]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47                      [32, 512, 12, 12]         1,024\n",
       "│    │    └─ReLU: 3-48                             [32, 512, 12, 12]         --\n",
       "│    │    └─Conv2d: 3-49                           [32, 512, 12, 12]         2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50                      [32, 512, 12, 12]         1,024\n",
       "│    │    └─CBAMWithMaskSupervision: 3-51          [32, 512, 12, 12]         32,866\n",
       "│    │    └─ReLU: 3-52                             [32, 512, 12, 12]         --\n",
       "├─AdaptiveAvgPool2d: 1-9                           [32, 512, 1, 1]           --\n",
       "├─Linear: 1-10                                     [32, 2]                   1,026\n",
       "====================================================================================================\n",
       "Total params: 11,204,132\n",
       "Trainable params: 11,204,132\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 163.15\n",
       "====================================================================================================\n",
       "Input size (MB): 18.87\n",
       "Forward/backward pass size (MB): 3737.44\n",
       "Params size (MB): 44.82\n",
       "Estimated Total Size (MB): 3801.13\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(net, input_size=(batch_size,1, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a98ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "mse = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "training_info=[[\"epoch\",\"acc\",\"loss\"]]\n",
    "testing_info=training_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1e321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train()\n",
    "    train_loss = np.zeros(3)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(trainloader)\n",
    "    for batch_idx, (inputs, targets, masks) in enumerate(pbar):\n",
    "        inputs, targets, masks = inputs.to(device), targets.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # outputs = net(inputs)\n",
    "        outputs, attn_map = net(inputs)\n",
    "        cls_loss = criterion(outputs, targets)\n",
    "        masks = F.adaptive_avg_pool2d(masks, attn_map.shape[-2:])\n",
    "        att_loss = 10.* mse(attn_map , masks)\n",
    "        \n",
    "        loss =  cls_loss + att_loss\n",
    "        \n",
    "        # loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += np.array([loss.item(), cls_loss.item(), att_loss.item()])\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        pbar.set_description(f\"Epoch: {epoch} Acc: {(100.*correct/total):.2f}\")\n",
    "\n",
    "    train_acc = 100.*correct/total\n",
    "    train_loss = train_loss/(batch_idx+1)\n",
    "    print(f\"Tot Loss: {train_loss[0]:.4f} CL: {train_loss[1]:.5f} AT: {train_loss[2]:.5f}; Train Acc: {train_acc:.2f}%\")\n",
    "    training_info.append([epoch,train_acc,train_loss])\n",
    "    # trainning_accuracy.append(train_acc)\n",
    "    # trainning_loss.append( train_loss )\n",
    "\n",
    "def test(epoch, islast = False):\n",
    "    global best_acc, best_epoch\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(testloader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets ) in enumerate(pbar):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        test_acc = 100.*correct/total\n",
    "        test_loss = test_loss/(batch_idx+1)\n",
    "        print(f\"Test Loss: {test_loss}, Test Acc: {test_acc:.2f}%\")\n",
    "        testing_info.append([epoch,test_acc,test_loss])\n",
    "        # testing_accuracy.append(test_acc)\n",
    "        # testing_loss.append(test_loss)\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc or islast:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        savestr = 'best' if acc > best_acc else 'last'\n",
    "        torch.save(state, os.path.join(result_dir,f'basel0-b{batch_size}-epoch{epoch}-{savestr}.pth'))\n",
    "        best_acc = acc\n",
    "        best_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af11cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros(3)\n",
    "aa = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e93a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Acc: 56.03: 100%|██████████| 172/172 [00:36<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.9554 CL: 0.68296 AT: 0.27246; Train Acc: 56.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6628181692716237, Test Acc: 60.28%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Acc: 63.51: 100%|██████████| 172/172 [00:39<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.8599 CL: 0.64284 AT: 0.21707; Train Acc: 63.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6072840742968224, Test Acc: 67.84%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Acc: 69.10: 100%|██████████| 172/172 [00:38<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.7801 CL: 0.58961 AT: 0.19047; Train Acc: 69.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5747128414946634, Test Acc: 71.20%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Acc: 71.50: 100%|██████████| 172/172 [00:39<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.7312 CL: 0.55506 AT: 0.17612; Train Acc: 71.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:07<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5549086267883713, Test Acc: 73.15%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Acc: 74.30: 100%|██████████| 172/172 [00:38<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.7006 CL: 0.53122 AT: 0.16939; Train Acc: 74.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5339989392338572, Test Acc: 74.38%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Acc: 76.27: 100%|██████████| 172/172 [00:37<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.6606 CL: 0.49542 AT: 0.16516; Train Acc: 76.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.506007073296083, Test Acc: 75.70%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Acc: 78.40: 100%|██████████| 172/172 [00:37<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.6253 CL: 0.46449 AT: 0.16079; Train Acc: 78.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:08<00:00,  8.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5628580302000046, Test Acc: 72.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Acc: 80.47: 100%|██████████| 172/172 [00:37<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.5980 CL: 0.43783 AT: 0.16014; Train Acc: 80.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4986705691427798, Test Acc: 76.51%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Acc: 81.95: 100%|██████████| 172/172 [00:37<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.5611 CL: 0.40694 AT: 0.15415; Train Acc: 81.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.45858245282559784, Test Acc: 78.93%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Acc: 83.80: 100%|██████████| 172/172 [00:37<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.5204 CL: 0.36679 AT: 0.15362; Train Acc: 83.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:08<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4423719249867104, Test Acc: 80.12%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Acc: 85.53: 100%|██████████| 172/172 [00:36<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.4915 CL: 0.33910 AT: 0.15244; Train Acc: 85.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.44048896150009054, Test Acc: 80.50%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Acc: 86.97: 100%|██████████| 172/172 [00:37<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.4554 CL: 0.30477 AT: 0.15066; Train Acc: 86.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4229389060590718, Test Acc: 80.80%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Acc: 88.57: 100%|██████████| 172/172 [00:36<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.4277 CL: 0.27798 AT: 0.14974; Train Acc: 88.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:08<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5459978274396948, Test Acc: 75.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Acc: 89.41: 100%|██████████| 172/172 [00:37<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.4086 CL: 0.26077 AT: 0.14787; Train Acc: 89.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:07<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.44098464621079936, Test Acc: 81.22%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Acc: 90.37: 100%|██████████| 172/172 [00:37<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.3843 CL: 0.23772 AT: 0.14658; Train Acc: 90.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.500465494152662, Test Acc: 80.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Acc: 91.26: 100%|██████████| 172/172 [00:41<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.3693 CL: 0.22508 AT: 0.14418; Train Acc: 91.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:05<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5137602384831454, Test Acc: 77.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Acc: 91.83: 100%|██████████| 172/172 [00:38<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.3402 CL: 0.19853 AT: 0.14167; Train Acc: 91.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:06<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.41689552195571566, Test Acc: 82.29%\n",
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Acc: 93.14: 100%|██████████| 172/172 [00:46<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot Loss: 0.3216 CL: 0.18123 AT: 0.14041; Train Acc: 93.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:07<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4713629484176636, Test Acc: 80.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Acc: 93.33:   9%|▊         | 15/172 [00:04<00:32,  4.87it/s]"
     ]
    }
   ],
   "source": [
    "if start_epoch>0:\n",
    "    checkpoint = torch.load(glob.glob(os.path.join(result_dir,f'basel0-b{batch_size}-epoch{start_epoch-1}-*.pth'))[0] )\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch+50):\n",
    "    train(epoch)\n",
    "    test(epoch, islast = epoch==start_epoch+49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7663ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame(training_info[1:],columns=training_info[0])\n",
    "testdf = pd.DataFrame(testing_info[1:],columns=testing_info[0])\n",
    "with open(os.path.join(result_dir,f'basel0-b{batch_size}-info.pkl'), 'wb') as file:\n",
    "    pickle.dump({\"train\":traindf,\"test\":testdf}, file)\n",
    "\n",
    " \n",
    " #   scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2a837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "levels = re.findall(r'MGA(\\d+)','MGA22')\n",
    "mga_level = int(levels[0]) if levels else 3\n",
    "# 'MGA3'.startswith('MGA')\n",
    "mga_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6b611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190325e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62.149533</td>\n",
       "      <td>0.649075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>66.482583</td>\n",
       "      <td>0.609698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71.750212</td>\n",
       "      <td>0.566307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72.982158</td>\n",
       "      <td>0.542833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>73.831776</td>\n",
       "      <td>0.516786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>75.615973</td>\n",
       "      <td>0.516502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>74.171623</td>\n",
       "      <td>0.512959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>71.070518</td>\n",
       "      <td>0.566263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>79.864061</td>\n",
       "      <td>0.427543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>79.099405</td>\n",
       "      <td>0.479788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>78.419711</td>\n",
       "      <td>0.463540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>80.033985</td>\n",
       "      <td>0.450472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>78.504673</td>\n",
       "      <td>0.493726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>79.566695</td>\n",
       "      <td>0.489486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>80.501274</td>\n",
       "      <td>0.525726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>83.050127</td>\n",
       "      <td>0.435180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>82.667799</td>\n",
       "      <td>0.427907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>84.027188</td>\n",
       "      <td>0.420336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>83.687341</td>\n",
       "      <td>0.436499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>83.347494</td>\n",
       "      <td>0.420859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>83.899745</td>\n",
       "      <td>0.442732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>84.112150</td>\n",
       "      <td>0.442911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>85.811385</td>\n",
       "      <td>0.411511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>80.501274</td>\n",
       "      <td>0.559405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>83.899745</td>\n",
       "      <td>0.461633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>85.386576</td>\n",
       "      <td>0.450221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>85.004248</td>\n",
       "      <td>0.432316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>84.961767</td>\n",
       "      <td>0.476926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>84.876805</td>\n",
       "      <td>0.480118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>84.282073</td>\n",
       "      <td>0.479020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>85.726423</td>\n",
       "      <td>0.447231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>85.089210</td>\n",
       "      <td>0.497021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>82.285472</td>\n",
       "      <td>0.533713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>84.409516</td>\n",
       "      <td>0.494975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>81.180969</td>\n",
       "      <td>0.638848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>84.621920</td>\n",
       "      <td>0.587297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>83.984707</td>\n",
       "      <td>0.570967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>85.046729</td>\n",
       "      <td>0.552302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>85.471538</td>\n",
       "      <td>0.506285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>84.579439</td>\n",
       "      <td>0.486658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>84.834325</td>\n",
       "      <td>0.519239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>85.046729</td>\n",
       "      <td>0.499402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>86.193713</td>\n",
       "      <td>0.434764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>85.004248</td>\n",
       "      <td>0.526764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>85.089210</td>\n",
       "      <td>0.574479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>85.598980</td>\n",
       "      <td>0.498157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>84.621920</td>\n",
       "      <td>0.552679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>85.301614</td>\n",
       "      <td>0.489806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>86.066270</td>\n",
       "      <td>0.498301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>86.108751</td>\n",
       "      <td>0.505942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch        acc      loss\n",
       "0       0  62.149533  0.649075\n",
       "1       1  66.482583  0.609698\n",
       "2       2  71.750212  0.566307\n",
       "3       3  72.982158  0.542833\n",
       "4       4  73.831776  0.516786\n",
       "5       5  75.615973  0.516502\n",
       "6       6  74.171623  0.512959\n",
       "7       7  71.070518  0.566263\n",
       "8       8  79.864061  0.427543\n",
       "9       9  79.099405  0.479788\n",
       "10     10  78.419711  0.463540\n",
       "11     11  80.033985  0.450472\n",
       "12     12  78.504673  0.493726\n",
       "13     13  79.566695  0.489486\n",
       "14     14  80.501274  0.525726\n",
       "15     15  83.050127  0.435180\n",
       "16     16  82.667799  0.427907\n",
       "17     17  84.027188  0.420336\n",
       "18     18  83.687341  0.436499\n",
       "19     19  83.347494  0.420859\n",
       "20     20  83.899745  0.442732\n",
       "21     21  84.112150  0.442911\n",
       "22     22  85.811385  0.411511\n",
       "23     23  80.501274  0.559405\n",
       "24     24  83.899745  0.461633\n",
       "25     25  85.386576  0.450221\n",
       "26     26  85.004248  0.432316\n",
       "27     27  84.961767  0.476926\n",
       "28     28  84.876805  0.480118\n",
       "29     29  84.282073  0.479020\n",
       "30     30  85.726423  0.447231\n",
       "31     31  85.089210  0.497021\n",
       "32     32  82.285472  0.533713\n",
       "33     33  84.409516  0.494975\n",
       "34     34  81.180969  0.638848\n",
       "35     35  84.621920  0.587297\n",
       "36     36  83.984707  0.570967\n",
       "37     37  85.046729  0.552302\n",
       "38     38  85.471538  0.506285\n",
       "39     39  84.579439  0.486658\n",
       "40     40  84.834325  0.519239\n",
       "41     41  85.046729  0.499402\n",
       "42     42  86.193713  0.434764\n",
       "43     43  85.004248  0.526764\n",
       "44     44  85.089210  0.574479\n",
       "45     45  85.598980  0.498157\n",
       "46     46  84.621920  0.552679\n",
       "47     47  85.301614  0.489806\n",
       "48     48  86.066270  0.498301\n",
       "49     49  86.108751  0.505942"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb143804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('two_dfs.pkl', 'rb') as file:\n",
    "#     loaded = pickle.load(file)\n",
    "\n",
    "# loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
